{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "heated-welding",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Python 的 50+ 練習：資料科學學習手冊\n",
    "\n",
    "> 監督式學習\n",
    "\n",
    "[數據交點](https://www.datainpoint.com) | 郭耀仁 <yaojenkuo@datainpoint.com>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-tokyo",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 練習題指引\n",
    "\n",
    "- 練習題閒置超過 10 分鐘會自動斷線，只要重新點選練習題連結即可重新啟動。\n",
    "- 第一個程式碼儲存格會將可能用得到的模組載入。\n",
    "- 如果練習題需要載入檔案，檔案存放絕對路徑為 `/home/jovyan/data`\n",
    "- 練習題已經給定函數、類別、預期輸入或參數名稱，我們只需要寫作程式區塊。同時也給定函數的類別提示，說明預期輸入以及預期輸出的類別。\n",
    "- 說明（Docstring）會描述測試如何進行，閱讀說明能夠暸解預期輸入以及預期輸出之間的關係，幫助我們更快解題。\n",
    "- 請在 `### BEGIN SOLUTION` 與 `### END SOLUTION` 這兩個註解之間寫作函數或者類別的程式區塊。\n",
    "- 將預期輸出放置在 `return` 保留字之後，若只是用 `print()` 函數將預期輸出印出無法通過測試。\n",
    "- 語法錯誤（`SyntaxError`）或縮排錯誤（`IndentationError`）等將會導致測試失效，測試之前應該先在筆記本使用函數觀察是否與說明（Docstring）描述的功能相符。\n",
    "- 如果卡關，可以先看練習題詳解或者複習課程單元影片之後再繼續寫作。\n",
    "- 執行測試的步驟：\n",
    "    1. 點選上方選單的 File -> Save Notebook 儲存 exercises.ipynb。\n",
    "    2. 點選上方選單的 File -> New -> Terminal 開啟終端機。\n",
    "    3. 在 Terminal 輸入 `cd ~` 切換回家目錄。\n",
    "    4. 在 Terminal 輸入 `python 20-supervised-learning/test_runner.py` 後按下 Enter 執行測試。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "collected-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebdd825",
   "metadata": {},
   "source": [
    "## 181. 載入 `house-prices` 中的 `train.csv` 與 `test.csv`\n",
    "\n",
    "定義函數 `import_house_prices()` 將位於 `/home/jovyan/data/house-prices` 路徑的 `train.csv` 與 `test.csv` 載入。\n",
    "\n",
    "來源：<https://www.kaggle.com/c/house-prices-advanced-regression-techniques>\n",
    "\n",
    "- 運用絕對路徑。\n",
    "- 使用 `pd.read_csv()` 函數。\n",
    "- 將預期輸出寫在 `return` 之後。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ddcd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_house_prices() -> tuple:\n",
    "    \"\"\"\n",
    "    >>> train, test = import_house_prices()\n",
    "    >>> type(train)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> type(test)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> train.shape\n",
    "    (1460, 81)\n",
    "    >>> test.shape\n",
    "    (1459, 80)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    path_train = '/Users/yitinglu/Documents/PythonCourses/data/train.csv'\n",
    "    path_test = '/Users/yitinglu/Documents/PythonCourses/data/test.csv'\n",
    "    train = pd.read_csv(path_train)\n",
    "    test = pd.read_csv(path_test)\n",
    "    return train, test\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06ee1da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
       "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal     208500  \n",
       "1         5   2007        WD         Normal     181500  \n",
       "2         9   2008        WD         Normal     223500  \n",
       "3         2   2006        WD        Abnorml     140000  \n",
       "4        12   2008        WD         Normal     250000  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "1455      8   2007        WD         Normal     175000  \n",
       "1456      2   2010        WD         Normal     210000  \n",
       "1457      5   2010        WD         Normal     266500  \n",
       "1458      4   2010        WD         Normal     142125  \n",
       "1459      6   2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, test = import_house_prices()\n",
    "# type(train)\n",
    "# type(test)\n",
    "# train.shape\n",
    "# test.shape\n",
    "#train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4402af4",
   "metadata": {},
   "source": [
    "## 182. 找出 `house-prices` 目標陣列欄位\n",
    "\n",
    "定義函數 `find_target_array_variable_house_prices()` 將 `train.csv` 與 `test.csv` 差別的欄位找出來。\n",
    "\n",
    "- 使用 `import_house_prices()` 函數。\n",
    "- 運用 `DataFrame.columns` 的集合運算特性。\n",
    "- 將預期輸出寫在 `return` 之後。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "493b462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_target_array_variable_house_prices() -> pd.core.indexes.base.Index:\n",
    "    \"\"\"\n",
    "    >>> target_array_variable_house_prices = find_target_array_variable_house_prices()\n",
    "    >>> target_array_variable_house_prices\n",
    "    Index(['SalePrice'], dtype='object')\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    train, test = import_house_prices()\n",
    "    mutual = train.columns ^ test.columns\n",
    "    return mutual\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ff1cd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qf/4fsz_nrd4mn7282yrvnt2k200000gn/T/ipykernel_14274/4100402886.py:9: FutureWarning: Index.__xor__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__xor__.  Use index.symmetric_difference(other) instead\n",
      "  mutual = train.columns ^ test.columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['SalePrice'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target_array_variable_house_prices = find_target_array_variable_house_prices()\n",
    "# target_array_variable_house_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf4b211",
   "metadata": {},
   "source": [
    "## 183. 選擇 `house-prices` 目標陣列與特徵矩陣\n",
    "\n",
    "定義函數 `extract_target_array_feature_matrix_house_prices()` 以 `train.csv` 中的 `SalePrice` 作為目標陣列 $y$、`OverallQual` 作為特徵矩陣 $X$\n",
    "\n",
    "- 使用 `import_house_prices()` 函數。\n",
    "- 運用選擇欄位技巧。\n",
    "- 注意特徵矩陣外型。\n",
    "- 將預期輸出寫在 `return` 之後。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43ab070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_target_array_feature_matrix_house_prices() -> tuple:\n",
    "    \"\"\"\n",
    "    >>> y, X = extract_target_array_feature_matrix_house_prices()\n",
    "    >>> type(y)\n",
    "    numpy.ndarray\n",
    "    >>> type(X)\n",
    "    numpy.ndarray\n",
    "    >>> y.shape\n",
    "    (1460,)\n",
    "    >>> X.shape\n",
    "    (1460, 1)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    train, test = import_house_prices()\n",
    "    y = train['SalePrice']\n",
    "    X = train['OverallQual'].values.reshape(-1, 1) #先用.values換成array list，再用reshape轉成固定只有一欄的array\n",
    "    return y, X\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9707ffa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y, X = extract_target_array_feature_matrix_house_prices()\n",
    "# X\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f3d998",
   "metadata": {},
   "source": [
    "## 184. 切割 `house-prices` 訓練與驗證資料\n",
    "\n",
    "定義函數 `split_train_valid_house_prices()` 將 `extract_target_array_feature_matrix_house_prices()` 函數所輸出的 $y$ 與 $X$ 切割為訓練與驗證資料。\n",
    "\n",
    "- 使用 `train_test_split(test_size=0.3, random_state=42)` 函數。\n",
    "- 將預期輸出寫在 `return` 之後。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33c62b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_valid_house_prices(X: np.ndarray, y: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    >>> y, X = extract_target_array_feature_matrix_house_prices()\n",
    "    >>> X_train, X_valid, y_train, y_valid = split_train_valid_house_prices(X, y)\n",
    "    >>> X_train.shape\n",
    "    (1022, 1)\n",
    "    >>> X_valid.shape\n",
    "    (438, 1)\n",
    "    >>> y_train.shape\n",
    "    (1022,)\n",
    "    >>> y_valid.shape\n",
    "    (438,)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42) #設置random_state是使種子結果每次都相同（為了通過作業測試）\n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y, X = extract_target_array_feature_matrix_house_prices()\n",
    "# X_train, X_valid, y_train, y_valid = split_train_valid_house_prices(X, y)\n",
    "# X_train.shape\n",
    "# X_valid.shape\n",
    "# y_train.shape\n",
    "# y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc1a276",
   "metadata": {},
   "source": [
    "## 185. 建立 `house-prices` 虛假模型\n",
    "\n",
    "定義類別 `DummyModelHousePrices` 用來建立具有兩個方法 `fit()`、`predict()` 的物件，能夠在 `split_train_valid_house_prices()` 函數所輸出 $y^{train}$ 最小值與最大值之間取隨機整數，建立虛假模型預測 $\\hat{y}$\n",
    "\n",
    "- 使用 `self`\n",
    "- 以 `self.attribute` 在類別程式區塊中使用屬性。\n",
    "- 以 `self.method()` 在類別程式區塊中使用方法。\n",
    "- 使用 `ndarray.min()` 與 `ndarray.max()`\n",
    "- 使用 `np.random.randint()` 函數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b50a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyModelHousePrices:\n",
    "    \"\"\"\n",
    "    >>> y, X = extract_target_array_feature_matrix_house_prices()\n",
    "    >>> X_train, X_valid, y_train, y_valid = split_train_valid_house_prices(X, y)\n",
    "    >>> dummy_model_house_prices = DummyModelHousePrices()\n",
    "    >>> dummy_model_house_prices.fit(y_train)\n",
    "    >>> y_hat = dummy_model_house_prices.predict(X_valid)\n",
    "    >>> type(y_hat)\n",
    "    numpy.ndarray\n",
    "    >>> y_hat.shape\n",
    "    (438,)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    #使用虛假模型，只是從售價(y)裡面挑出範圍內的隨機亂數，然後最後去配對總體品質（X) == y售價隨便亂取，然後就去對答案\n",
    "    def fit(self, y_train):\n",
    "        self.y_train_max = y_train.max()\n",
    "        self.y_train_min = y_train.min()\n",
    "    def predict(self, X_valid):\n",
    "        y_hat = np.random.randint(self.y_train_min, self.y_train_max, X_valid.shape[0]) #最小, 最大, size=X_valid.列數（因為shape=>(m,n))\n",
    "        return y_hat\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f0ba9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y, X = extract_target_array_feature_matrix_house_prices()\n",
    "# X_train, X_valid, y_train, y_valid = split_train_valid_house_prices(X, y)\n",
    "# dummy_model_house_prices = DummyModelHousePrices()\n",
    "# dummy_model_house_prices.fit(y_train)\n",
    "# y_hat = dummy_model_house_prices.predict(X_valid)\n",
    "# type(y_hat)\n",
    "# y_hat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406364ed",
   "metadata": {},
   "source": [
    "## 186. 建立 `house-prices` 專家模型\n",
    "\n",
    "定義類別 `ExpertModelHousePrices` 用來建立具有兩個方法 `fit()`、`predict()` 的物件，能夠依據 `split_train_valid_house_prices()` 函數所輸出 $X^{train}$ 與 $y^{train}$ 建立專家模型，以 `OverallQual` 分組，聚合 `SalePrice` 的平均數，以分組聚合的對應關係預測 $\\hat{y}$\n",
    "\n",
    "- 使用 `self`\n",
    "- 以 `self.attribute` 在類別程式區塊中使用屬性。\n",
    "- 以 `self.method()` 在類別程式區塊中使用方法。\n",
    "- 使用分組聚合技巧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "16700dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpertModelHousePrices:\n",
    "    \"\"\"\n",
    "    >>> y, X = extract_target_array_feature_matrix_house_prices()\n",
    "    >>> X_train, X_valid, y_train, y_valid = split_train_valid_house_prices(X, y)\n",
    "    >>> expert_model_house_prices = ExpertModelHousePrices()\n",
    "    >>> expert_model_house_prices.fit(X_train, y_train)\n",
    "    OverallQual\n",
    "    1      50150.000000\n",
    "    2      60000.000000\n",
    "    3      85950.000000\n",
    "    4     107983.750000\n",
    "    5     133982.099617\n",
    "    6     162075.261993\n",
    "    7     206433.647826\n",
    "    8     274112.188525\n",
    "    9     355825.366667\n",
    "    10    437396.454545\n",
    "    Name: SalePrice, dtype: float64\n",
    "    >>> y_hat = expert_model_house_prices.predict(X_valid)\n",
    "    >>> type(y_hat)\n",
    "    numpy.ndarray\n",
    "    >>> y_hat.shape\n",
    "    (438,)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    #使用專家模型，用訓練資料集中的品質（X)和售價(y)計算，然後最後去對答案看測試資料（X)。\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        dataf = pd.DataFrame()\n",
    "        dataf['SalePrice'] = self.y_train\n",
    "        dataf['OverallQual'] = self.X_train\n",
    "        self.data_mean = dataf.groupby(['OverallQual'])['SalePrice'].mean()\n",
    "        return self.data_mean\n",
    "    def predict(self, X_valid):\n",
    "        X_valid_ravel = X_valid.ravel() #用ravel()把Series一維化\n",
    "        y_hat = list(map(lambda x: self.data_mean[x], X_valid_ravel)) \n",
    "        #lambda x: self.data_mean[x]會走訪X_valid_ravel中每個元素，並透過map應用方法\n",
    "        return np.array(y_hat)\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fe566c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y, X = extract_target_array_feature_matrix_house_prices()\n",
    "# X_train, X_valid, y_train, y_valid = split_train_valid_house_prices(X, y)\n",
    "# expert_model_house_prices = ExpertModelHousePrices()\n",
    "# expert_model_house_prices.fit(X_train, y_train)\n",
    "# y_hat = expert_model_house_prices.predict(X_valid)\n",
    "# type(y_hat)\n",
    "# y_hat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a2b2dd",
   "metadata": {},
   "source": [
    "## 187. 建立 `house-prices` 基於機器學習的模型\n",
    "\n",
    "定義類別 `MachineLearningModelHousePrices` 用來建立具有兩個方法 `fit()`、`predict()` 的物件，能夠依據 `split_train_valid_house_prices()` 函數所輸出 $X^{train}$ 與 $y^{train}$ 建立基於機器學習的模型，直接使用 Scikit-Learn `LinearRegression` 類別 `fit()` 與 `predict()` 方法預測 $\\hat{y}$\n",
    "\n",
    "- 使用 `self`\n",
    "- 以 `self.attribute` 在類別程式區塊中使用屬性。\n",
    "- 以 `self.method()` 在類別程式區塊中使用方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cd93795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MachineLearningModelHousePrices:\n",
    "    \"\"\"\n",
    "    >>> y, X = extract_target_array_feature_matrix_house_prices()\n",
    "    >>> X_train, X_valid, y_train, y_valid = split_train_valid_house_prices(X, y)\n",
    "    >>> machine_learning_model_house_prices = MachineLearningModelHousePrices()\n",
    "    >>> machine_learning_model_house_prices.fit(X_train, y_train)\n",
    "    LinearRegression()\n",
    "    >>> y_hat = machine_learning_model_house_prices.predict(X_valid)\n",
    "    >>> type(y_hat)\n",
    "    numpy.ndarray\n",
    "    >>> y_hat.shape\n",
    "    (438,)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    def fit(self, X_train, y_train):\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X_train, y_train)    #只要用.fit(x,y)就會自動訓練模型了，並「不需要」賦值給其他變數\n",
    "        self.model = lr\n",
    "        return lr\n",
    "    def predict(self, X_valid):\n",
    "        y_hat = self.model.predict(X_valid)     #predict 可以直接拿來用於預測原本寫好的模型\n",
    "        return y_hat\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0d6fbbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y, X = extract_target_array_feature_matrix_house_prices()\n",
    "# X_train, X_valid, y_train, y_valid = split_train_valid_house_prices(X, y)\n",
    "# machine_learning_model_house_prices = MachineLearningModelHousePrices()\n",
    "# machine_learning_model_house_prices.fit(X_train, y_train)\n",
    "# y_hat = machine_learning_model_house_prices.predict(X_valid)\n",
    "# type(y_hat)\n",
    "# y_hat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e405432",
   "metadata": {},
   "source": [
    "## 188. 驗證 `house-prices` 的三個模型\n",
    "\n",
    "定義函數 `validate_model_performance_house_prices()` 能夠依據 `split_train_valid_house_prices()` 函數所輸出 $y^{valid}$，計算虛假模型、專家模型與基於機器學習模型的表現評估。\n",
    "\n",
    "- 使用 `mean_squared_error()` 函數。\n",
    "- 將預期輸出寫在 `return` 之後。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "03fae71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model_performance_house_prices(dummy_y_hat: np.ndarray,\n",
    "                                            expert_y_hat: np.ndarray,\n",
    "                                            machine_learning_y_hat: np.ndarray,\n",
    "                                            y_valid: np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    >>> y, X = extract_target_array_feature_matrix_house_prices()\n",
    "    >>> X_train, X_valid, y_train, y_valid = split_train_valid_house_prices(X, y)\n",
    "    >>> dummy_model_house_prices = DummyModelHousePrices()\n",
    "    >>> dummy_model_house_prices.fit(y_train)\n",
    "    >>> dummy_y_hat = dummy_model_house_prices.predict(X_valid)\n",
    "    >>> expert_model_house_prices = ExpertModelHousePrices()\n",
    "    >>> expert_model_house_prices.fit(X_train, y_train)\n",
    "    OverallQual\n",
    "    1      50150.000000\n",
    "    2      60000.000000\n",
    "    3      85950.000000\n",
    "    4     107983.750000\n",
    "    5     133982.099617\n",
    "    6     162075.261993\n",
    "    7     206433.647826\n",
    "    8     274112.188525\n",
    "    9     355825.366667\n",
    "    10    437396.454545\n",
    "    Name: SalePrice, dtype: float64\n",
    "    >>> expert_y_hat = expert_model_house_prices.predict(X_valid)\n",
    "    >>> machine_learning_model_house_prices = MachineLearningModelHousePrices()\n",
    "    >>> machine_learning_model_house_prices.fit(X_train, y_train)\n",
    "    LinearRegression()\n",
    "    >>> machine_learning_y_hat = machine_learning_model_house_prices.predict(X_valid)\n",
    "    >>> validate_model_performance_house_prices(dummy_y_hat, expert_y_hat, machine_learning_y_hat, y_valid)\n",
    "    {'dummy': 95083333626.51826,\n",
    "     'expert': 2023633279.0004246,\n",
    "     'machine_learning': 2483429086.6514378}\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    dummy = mean_squared_error(dummy_y_hat, y_valid)\n",
    "    expert = mean_squared_error(expert_y_hat, y_valid)\n",
    "    machine_learning = mean_squared_error(machine_learning_y_hat, y_valid)\n",
    "    result = dict()\n",
    "    result = {'dummy': dummy , 'expert': expert,'machine_learning': machine_learning}\n",
    "    return result\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d95415e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dummy': 93644943451.6758,\n",
       " 'expert': 2023633279.0004246,\n",
       " 'machine_learning': 2483429086.651439}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy_y_hat = dummy_model_house_prices.predict(X_valid)\n",
    "# expert_y_hat = expert_model_house_prices.predict(X_valid)\n",
    "# machine_learning_y_hat = machine_learning_model_house_prices.predict(X_valid)\n",
    "# validate_model_performance_house_prices(dummy_y_hat, expert_y_hat, machine_learning_y_hat, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4092d75",
   "metadata": {},
   "source": [
    "## 189. 以 `house-prices` 專家模型預測位於 `/home/jovyan/data/house-prices` 路徑的 `test.csv`\n",
    "\n",
    "定義函數 `predict_sale_price()` 能夠依據 `OverallQual` 與專家模型預測 `test.csv` 的 `SalePrice`\n",
    "\n",
    "- 使用 `import_house_prices()` 函數。\n",
    "- 使用 `extract_target_array_feature_matrix_house_prices()` 函數。\n",
    "- 使用 `split_train_valid_house_prices()` 函數。\n",
    "- 使用 `ExpertModelHousePrices` 類別。\n",
    "- 將預期輸出寫在 `return` 之後。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "22fba203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sale_price(X_test: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    >>> train, test = import_house_prices()\n",
    "    >>> X_test = test[[\"Id\", \"OverallQual\"]]\n",
    "    >>> predict_sale_price(X_test)\n",
    "            Id      SalePrice\n",
    "    0     1461  133982.099617\n",
    "    1     1462  162075.261993\n",
    "    2     1463  133982.099617\n",
    "    3     1464  162075.261993\n",
    "    4     1465  274112.188525\n",
    "    ...    ...            ...\n",
    "    1454  2915  107983.750000\n",
    "    1455  2916  107983.750000\n",
    "    1456  2917  133982.099617\n",
    "    1457  2918  133982.099617\n",
    "    1458  2919  206433.647826\n",
    "\n",
    "    [1459 rows x 2 columns]\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    #train, test = import_house_prices()\n",
    "    y, X = extract_target_array_feature_matrix_house_prices()\n",
    "    X_train, X_valid, y_train, y_valid = split_train_valid_house_prices(X, y)\n",
    "    expert_model = ExpertModelHousePrices()\n",
    "    expert_model.fit(X_train, y_train)\n",
    "    X_test_data = X_test['OverallQual'].values.reshape(-1,1)\n",
    "    X_test_predict = expert_model.predict(X_test_data)\n",
    "    result = pd.DataFrame()\n",
    "    result['Id'] = X_test['Id']\n",
    "    result['SalePrice'] = X_test_predict\n",
    "    return result\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "32b1f139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>133982.099617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>162075.261993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>133982.099617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>162075.261993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>274112.188525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>107983.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>107983.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>133982.099617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>133982.099617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>206433.647826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461  133982.099617\n",
       "1     1462  162075.261993\n",
       "2     1463  133982.099617\n",
       "3     1464  162075.261993\n",
       "4     1465  274112.188525\n",
       "...    ...            ...\n",
       "1454  2915  107983.750000\n",
       "1455  2916  107983.750000\n",
       "1456  2917  133982.099617\n",
       "1457  2918  133982.099617\n",
       "1458  2919  206433.647826\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, test = import_house_prices()\n",
    "# X_test = test[[\"Id\", \"OverallQual\"]]\n",
    "# predict_sale_price(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366f636e",
   "metadata": {},
   "source": [
    "## 190. 將 `house-prices` 專家模型預測結果輸出為 `submission_house_prices.csv`\n",
    "\n",
    "定義函數 `export_sale_price_as_submission()` 能夠將 `predict_sale_price()` 函數的輸出以 `submission_house_prices.csv` 格式匯出至工作目錄。\n",
    "\n",
    "- 使用 `predict_sale_price()` 函數。\n",
    "- 使用 `DataFrame.to_csv(\"submission_house_prices.csv\", index=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "518969fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_sale_price_as_submission(X_test: pd.core.frame.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    >>> train, test = import_house_prices()\n",
    "    >>> X_test = test[[\"Id\", \"OverallQual\"]]\n",
    "    >>> export_sale_price_as_submission(X_test)\n",
    "    >>> submission_csv = pd.read_csv(\"submission_house_prices.csv\")\n",
    "    >>> submission_csv.shape\n",
    "    (1459, 2)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    data = predict_sale_price(X_test)\n",
    "    data.to_csv(\"submission_house_prices.csv\", index = False)\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7b717a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 2)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, test = import_house_prices()\n",
    "# X_test = test[[\"Id\", \"OverallQual\"]]\n",
    "# export_sale_price_as_submission(X_test)\n",
    "# submission_csv = pd.read_csv(\"submission_house_prices.csv\")\n",
    "# submission_csv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4629f945",
   "metadata": {},
   "source": [
    "## 191. 載入 `titanic` 中的 `train.csv` 與 `test.csv`\n",
    "\n",
    "定義函數 `import_titanic()` 將位於 `/home/jovyan/data/titanic` 路徑的 `train.csv` 與 `test.csv` 載入。\n",
    "\n",
    "來源：<https://www.kaggle.com/c/titanic>\n",
    "\n",
    "- 運用絕對路徑。\n",
    "- 使用 `pd.read_csv()` 函數。\n",
    "- 將預期輸出寫在 `return` 之後。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b0b67f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_titanic() -> tuple:\n",
    "    \"\"\"\n",
    "    >>> train, test = import_titanic()\n",
    "    >>> type(train)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> type(test)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> train.shape\n",
    "    (891, 12)\n",
    "    >>> test.shape\n",
    "    (418, 11)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    path_train = '/Users/yitinglu/Documents/PythonCourses/data/titanic/train.csv'\n",
    "    path_test = '/Users/yitinglu/Documents/PythonCourses/data/titanic/test.csv'\n",
    "    train, test = pd.read_csv(path_train), pd.read_csv(path_test)\n",
    "    return train, test\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "77de3b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, test = import_titanic()\n",
    "# type(train)\n",
    "# train.shape\n",
    "# test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad7060e",
   "metadata": {},
   "source": [
    "## 192. 找出 `titanic` 目標陣列欄位\n",
    "\n",
    "定義函數 `find_target_array_variable_titanic()` 將 `train.csv` 與 `test.csv` 差別的欄位找出來。\n",
    "\n",
    "- 使用 `import_titanic()` 函數。\n",
    "- 運用 `DataFrame.columns` 的集合運算特性。\n",
    "- 將預期輸出寫在 `return` 之後。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7eb79d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_target_array_variable_titanic() -> pd.core.indexes.base.Index:\n",
    "    \"\"\"\n",
    "    >>> target_array_variable_titanic = find_target_array_variable_titanic()\n",
    "    >>> target_array_variable_titanic\n",
    "    Index(['Survived'], dtype='object')\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    train, test = import_titanic()\n",
    "    return train.columns ^ test.columns\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "420c3a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qf/4fsz_nrd4mn7282yrvnt2k200000gn/T/ipykernel_14274/2108909175.py:9: FutureWarning: Index.__xor__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__xor__.  Use index.symmetric_difference(other) instead\n",
      "  return train.columns ^ test.columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Survived'], dtype='object')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target_array_variable_titanic = find_target_array_variable_titanic()\n",
    "# target_array_variable_titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ff4623",
   "metadata": {},
   "source": [
    "## 193. 選擇 `titanic` 目標陣列與特徵矩陣\n",
    "\n",
    "定義函數 `extract_target_array_feature_matrix_titanic()` 以 `train.csv` 中的 `Survived` 作為目標陣列 $y$、`Sex`、`Age` 作為特徵矩陣 $X$\n",
    "\n",
    "- 使用 `import_titanic()` 函數。\n",
    "- 運用選擇欄位技巧。\n",
    "- 注意特徵矩陣外型。\n",
    "- 將預期輸出寫在 `return` 之後。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bef115c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_target_array_feature_matrix_titanic() -> tuple:\n",
    "    \"\"\"\n",
    "    >>> y, X = extract_target_array_feature_matrix_titanic()\n",
    "    >>> type(y)\n",
    "    numpy.ndarray\n",
    "    >>> type(X)\n",
    "    numpy.ndarray\n",
    "    >>> y.shape\n",
    "    (891,)\n",
    "    >>> X.shape\n",
    "    (891, 2)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    train, test = import_titanic()\n",
    "    y = train['Survived'].values\n",
    "    X = train[['Sex', 'Age']].values #放在同一個列表中，而不是分開變成多個列表\n",
    "    #X = train['Age'].values\n",
    "    X = X.reshape(-1,2)\n",
    "    return y, X\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "23042dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 2)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y, X = extract_target_array_feature_matrix_titanic()\n",
    "# type(y)\n",
    "# y.shape\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5866227",
   "metadata": {},
   "source": [
    "## 194. 操作 `titanic` 特徵矩陣\n",
    "\n",
    "定義函數 `wrangle_feature_matrix_titanic()` 將 `extract_target_array_feature_matrix_titanic()` 函數輸出的 `X` 第 0 欄轉換為整數、第 1 欄填補未定義值，轉換與填補的規則如下：\n",
    "\n",
    "- `{'female': 0, 'male': 1}`\n",
    "- 使用 `Series.map()`\n",
    "- 使用 `Series.mean()`\n",
    "- 使用 `Series.fillna()` 以平均數作為填補值。\n",
    "- 將預期輸出寫在 `return` 之後。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d306bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_feature_matrix_titanic(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    >>> y, X = extract_target_array_feature_matrix_titanic()\n",
    "    >>> X_wrangled = wrangle_feature_matrix_titanic(X)\n",
    "    >>> type(X_wrangled)\n",
    "    numpy.ndarray\n",
    "    >>> np.unique(X_wrangled[:, 0])\n",
    "    array([0., 1.])\n",
    "    >>> np.sum(np.isnan(X_wrangled[:, 1]))\n",
    "    0\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    X_df = pd.DataFrame(X)\n",
    "    gender_code = X_df[0].map(lambda x: 1 if x == 'male' else 0)    #成功轉換男女代碼\n",
    "    gender_mean = X_df[1].mean()\n",
    "    X_df[1] = X_df[1].fillna(gender_mean)\n",
    "    result = pd.DataFrame()\n",
    "    result['Sex'] = gender_code\n",
    "    result['Age'] = X_df[1]\n",
    "    return result.values #最後轉換成array\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f38430d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y, X = extract_target_array_feature_matrix_titanic()\n",
    "# X_wrangled = wrangle_feature_matrix_titanic(X)\n",
    "# X_wrangled\n",
    "# type(X_wrangled)\n",
    "# np.unique(X_wrangled[:, 0])\n",
    "# np.sum(np.isnan(X_wrangled[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85d5a65",
   "metadata": {},
   "source": [
    "## 195. 切割 `titanic` 訓練與驗證資料\n",
    "\n",
    "定義函數 `split_train_valid_titanic()` 將 `extract_target_array_feature_matrix_titanic()` 函數所輸出的 $y$ 與 `wrangle_feature_matrix_titanic()` 函數所輸出的 `X_wrangled` 切割為訓練與驗證資料。\n",
    "\n",
    "- 使用 `train_test_split(test_size=0.3, random_state=42)` 函數。\n",
    "- 將預期輸出寫在 `return` 之後。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "80772710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_valid_titanic(X: np.ndarray, y: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    >>> y, X = extract_target_array_feature_matrix_titanic()\n",
    "    >>> X_wrangled = wrangle_feature_matrix_titanic(X)\n",
    "    >>> X_train, X_valid, y_train, y_valid = split_train_valid_titanic(X_wrangled, y)\n",
    "    >>> X_train.shape\n",
    "    (623, 2)\n",
    "    >>> X_valid.shape\n",
    "    (268, 2)\n",
    "    >>> y_train.shape\n",
    "    (623,)\n",
    "    >>> y_valid.shape\n",
    "    (268,)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "2dc6e247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , 29.69911765],\n",
       "       [ 1.        , 31.        ],\n",
       "       [ 1.        , 20.        ],\n",
       "       [ 0.        ,  6.        ],\n",
       "       [ 0.        , 14.        ],\n",
       "       [ 0.        , 26.        ],\n",
       "       [ 0.        , 29.69911765],\n",
       "       [ 1.        , 16.        ],\n",
       "       [ 0.        , 16.        ],\n",
       "       [ 0.        , 19.        ],\n",
       "       [ 1.        , 37.        ],\n",
       "       [ 1.        , 44.        ],\n",
       "       [ 0.        , 29.69911765],\n",
       "       [ 1.        , 30.        ],\n",
       "       [ 1.        , 36.        ],\n",
       "       [ 0.        , 16.        ],\n",
       "       [ 1.        , 42.        ],\n",
       "       [ 0.        , 29.69911765],\n",
       "       [ 1.        , 27.        ],\n",
       "       [ 1.        , 47.        ],\n",
       "       [ 1.        , 24.        ],\n",
       "       [ 1.        , 34.        ],\n",
       "       [ 0.        , 19.        ],\n",
       "       [ 1.        , 20.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 10.        ],\n",
       "       [ 1.        , 40.        ],\n",
       "       [ 1.        , 31.        ],\n",
       "       [ 1.        ,  4.        ],\n",
       "       [ 0.        , 31.        ],\n",
       "       [ 1.        , 19.        ],\n",
       "       [ 0.        , 22.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 0.        , 29.69911765],\n",
       "       [ 1.        , 18.        ],\n",
       "       [ 1.        , 27.        ],\n",
       "       [ 1.        , 28.        ],\n",
       "       [ 0.        , 29.69911765],\n",
       "       [ 0.        , 30.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 21.        ],\n",
       "       [ 1.        , 29.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 0.        , 45.        ],\n",
       "       [ 1.        , 16.        ],\n",
       "       [ 1.        , 19.        ],\n",
       "       [ 1.        , 23.        ],\n",
       "       [ 1.        , 24.        ],\n",
       "       [ 1.        , 58.        ],\n",
       "       [ 0.        ,  5.        ],\n",
       "       [ 0.        , 52.        ],\n",
       "       [ 1.        , 40.        ],\n",
       "       [ 1.        , 11.        ],\n",
       "       [ 1.        , 65.        ],\n",
       "       [ 0.        , 18.        ],\n",
       "       [ 1.        , 32.        ],\n",
       "       [ 0.        , 50.        ],\n",
       "       [ 0.        , 35.        ],\n",
       "       [ 0.        , 19.        ],\n",
       "       [ 1.        , 21.        ],\n",
       "       [ 0.        , 13.        ],\n",
       "       [ 0.        , 28.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 0.        , 57.        ],\n",
       "       [ 1.        , 21.        ],\n",
       "       [ 1.        , 29.        ],\n",
       "       [ 1.        , 17.        ],\n",
       "       [ 0.        , 52.        ],\n",
       "       [ 0.        , 26.        ],\n",
       "       [ 0.        , 18.        ],\n",
       "       [ 1.        , 26.        ],\n",
       "       [ 0.        , 39.        ],\n",
       "       [ 1.        , 23.        ],\n",
       "       [ 1.        , 36.        ],\n",
       "       [ 0.        , 30.5       ],\n",
       "       [ 0.        , 22.        ],\n",
       "       [ 0.        , 38.        ],\n",
       "       [ 0.        , 41.        ],\n",
       "       [ 1.        , 16.        ],\n",
       "       [ 0.        , 29.        ],\n",
       "       [ 0.        , 40.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 56.        ],\n",
       "       [ 1.        , 71.        ],\n",
       "       [ 0.        , 31.        ],\n",
       "       [ 0.        , 30.        ],\n",
       "       [ 1.        , 38.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        ,  9.        ],\n",
       "       [ 0.        ,  9.        ],\n",
       "       [ 1.        , 61.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 28.        ],\n",
       "       [ 1.        , 48.        ],\n",
       "       [ 1.        , 45.        ],\n",
       "       [ 0.        , 36.        ],\n",
       "       [ 1.        , 27.        ],\n",
       "       [ 1.        , 64.        ],\n",
       "       [ 1.        , 35.        ],\n",
       "       [ 0.        , 19.        ],\n",
       "       [ 1.        , 38.        ],\n",
       "       [ 1.        , 30.5       ],\n",
       "       [ 1.        , 25.        ],\n",
       "       [ 0.        , 40.        ],\n",
       "       [ 1.        , 47.        ],\n",
       "       [ 1.        , 30.        ],\n",
       "       [ 1.        , 40.        ],\n",
       "       [ 0.        , 29.69911765],\n",
       "       [ 1.        , 20.5       ],\n",
       "       [ 0.        , 29.69911765],\n",
       "       [ 1.        , 36.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 20.        ],\n",
       "       [ 1.        , 71.        ],\n",
       "       [ 1.        , 36.        ],\n",
       "       [ 0.        , 22.        ],\n",
       "       [ 0.        , 48.        ],\n",
       "       [ 1.        , 23.        ],\n",
       "       [ 0.        , 32.        ],\n",
       "       [ 0.        , 63.        ],\n",
       "       [ 1.        ,  0.83      ],\n",
       "       [ 1.        , 25.        ],\n",
       "       [ 1.        , 35.        ],\n",
       "       [ 0.        , 49.        ],\n",
       "       [ 1.        , 24.        ],\n",
       "       [ 0.        , 29.69911765],\n",
       "       [ 1.        , 21.        ],\n",
       "       [ 0.        , 29.69911765],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 0.        ,  5.        ],\n",
       "       [ 1.        , 49.        ],\n",
       "       [ 0.        , 15.        ],\n",
       "       [ 0.        , 29.69911765],\n",
       "       [ 1.        , 29.        ],\n",
       "       [ 1.        , 42.        ],\n",
       "       [ 0.        , 18.        ],\n",
       "       [ 1.        , 21.        ],\n",
       "       [ 0.        , 44.        ],\n",
       "       [ 1.        , 28.        ],\n",
       "       [ 1.        , 37.        ],\n",
       "       [ 0.        , 39.        ],\n",
       "       [ 0.        , 34.        ],\n",
       "       [ 1.        , 30.        ],\n",
       "       [ 1.        , 66.        ],\n",
       "       [ 0.        , 29.69911765],\n",
       "       [ 1.        , 43.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 24.        ],\n",
       "       [ 1.        , 18.        ],\n",
       "       [ 0.        , 29.69911765],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 0.        , 29.69911765],\n",
       "       [ 0.        , 36.        ],\n",
       "       [ 0.        , 32.        ],\n",
       "       [ 1.        , 23.5       ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 39.        ],\n",
       "       [ 0.        , 29.69911765],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 65.        ],\n",
       "       [ 1.        , 23.        ],\n",
       "       [ 0.        , 29.69911765],\n",
       "       [ 1.        , 22.        ],\n",
       "       [ 1.        , 35.        ],\n",
       "       [ 1.        , 23.        ],\n",
       "       [ 0.        , 18.        ],\n",
       "       [ 1.        , 36.        ],\n",
       "       [ 0.        ,  9.        ],\n",
       "       [ 1.        , 17.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 0.        , 38.        ],\n",
       "       [ 0.        , 17.        ],\n",
       "       [ 0.        ,  4.        ],\n",
       "       [ 1.        , 45.5       ],\n",
       "       [ 1.        , 23.        ],\n",
       "       [ 1.        , 32.        ],\n",
       "       [ 1.        , 26.        ],\n",
       "       [ 0.        ,  6.        ],\n",
       "       [ 1.        , 24.        ],\n",
       "       [ 1.        , 45.        ],\n",
       "       [ 1.        , 29.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 0.        , 42.        ],\n",
       "       [ 1.        , 36.        ],\n",
       "       [ 1.        , 33.        ],\n",
       "       [ 1.        , 17.        ],\n",
       "       [ 1.        , 29.        ],\n",
       "       [ 0.        , 50.        ],\n",
       "       [ 0.        , 35.        ],\n",
       "       [ 0.        , 38.        ],\n",
       "       [ 1.        , 34.        ],\n",
       "       [ 0.        , 17.        ],\n",
       "       [ 0.        , 11.        ],\n",
       "       [ 1.        , 61.        ],\n",
       "       [ 0.        , 30.        ],\n",
       "       [ 0.        ,  7.        ],\n",
       "       [ 0.        , 63.        ],\n",
       "       [ 1.        , 20.        ],\n",
       "       [ 0.        , 29.69911765],\n",
       "       [ 1.        , 29.        ],\n",
       "       [ 1.        , 36.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 50.        ],\n",
       "       [ 1.        , 27.        ],\n",
       "       [ 1.        , 30.        ],\n",
       "       [ 0.        , 33.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 0.        , 29.69911765],\n",
       "       [ 1.        ,  2.        ],\n",
       "       [ 0.        , 25.        ],\n",
       "       [ 1.        , 51.        ],\n",
       "       [ 0.        , 25.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 0.        , 24.        ],\n",
       "       [ 1.        , 18.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 25.        ],\n",
       "       [ 0.        , 24.        ],\n",
       "       [ 1.        , 22.        ],\n",
       "       [ 1.        ,  0.92      ],\n",
       "       [ 0.        , 24.        ],\n",
       "       [ 0.        , 26.        ],\n",
       "       [ 1.        , 34.        ],\n",
       "       [ 0.        , 21.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 0.        , 29.69911765],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 0.        , 22.        ],\n",
       "       [ 0.        , 62.        ],\n",
       "       [ 0.        , 18.        ],\n",
       "       [ 0.        , 42.        ],\n",
       "       [ 1.        , 57.        ],\n",
       "       [ 1.        , 19.        ],\n",
       "       [ 0.        , 42.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 0.        , 20.        ],\n",
       "       [ 1.        , 34.5       ],\n",
       "       [ 1.        , 28.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 23.        ],\n",
       "       [ 1.        , 22.        ],\n",
       "       [ 1.        , 52.        ],\n",
       "       [ 0.        , 30.        ],\n",
       "       [ 1.        , 36.5       ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 22.        ],\n",
       "       [ 1.        , 50.        ],\n",
       "       [ 1.        , 27.        ],\n",
       "       [ 1.        , 22.        ],\n",
       "       [ 0.        , 51.        ],\n",
       "       [ 1.        , 36.        ],\n",
       "       [ 0.        , 29.        ],\n",
       "       [ 0.        , 22.        ],\n",
       "       [ 1.        , 50.        ],\n",
       "       [ 0.        , 40.        ],\n",
       "       [ 1.        , 27.        ],\n",
       "       [ 1.        , 29.69911765],\n",
       "       [ 1.        , 65.        ],\n",
       "       [ 1.        , 17.        ],\n",
       "       [ 1.        , 28.        ]])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y, X = extract_target_array_feature_matrix_titanic()\n",
    "# X_wrangled = wrangle_feature_matrix_titanic(X)\n",
    "# X_train, X_valid, y_train, y_valid = split_train_valid_titanic(X_wrangled, y)\n",
    "# X_train.shape\n",
    "# X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b92327e",
   "metadata": {},
   "source": [
    "## 196. 建立 `titanic` 虛假模型\n",
    "\n",
    "定義類別 `DummyModelTitanic` 用來建立具有兩個方法 `fit()`、`predict()` 的物件，能夠隨機生成整數 0 或 1，建立虛假模型預測 $\\hat{y}$\n",
    "\n",
    "- 使用 `self`\n",
    "- 以 `self.attribute` 在類別程式區塊中使用屬性。\n",
    "- 以 `self.method()` 在類別程式區塊中使用方法。\n",
    "- 使用 `np.random.randint()` 函數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b3367ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyModelTitanic:\n",
    "    \"\"\"\n",
    "    >>> y, X = extract_target_array_feature_matrix_titanic()\n",
    "    >>> X_wrangled = wrangle_feature_matrix_titanic(X)\n",
    "    >>> X_train, X_valid, y_train, y_valid = split_train_valid_titanic(X_wrangled, y)\n",
    "    >>> dummy_model_titanic = DummyModelTitanic()\n",
    "    >>> dummy_model_titanic.fit(y_train)\n",
    "    >>> y_hat = dummy_model_titanic.predict(X_valid)\n",
    "    >>> type(y_hat)\n",
    "    numpy.ndarray\n",
    "    >>> y_hat.shape\n",
    "    (268,)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    def fit(self, y_train):\n",
    "        self.y_train = y_train\n",
    "    def predict(self, X_valid):\n",
    "        y_hat = np.random.randint(0,2, X_valid.shape[0])   #要X_valid的列數而已，實際上值不重要\n",
    "        return y_hat\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b9874158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268,)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y, X = extract_target_array_feature_matrix_titanic()\n",
    "# X_wrangled = wrangle_feature_matrix_titanic(X)\n",
    "# X_train, X_valid, y_train, y_valid = split_train_valid_titanic(X_wrangled, y)\n",
    "# dummy_model_titanic = DummyModelTitanic()\n",
    "# dummy_model_titanic.fit(y_train)\n",
    "# y_hat = dummy_model_titanic.predict(X_valid)\n",
    "# type(y_hat)\n",
    "# y_hat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df6b831",
   "metadata": {},
   "source": [
    "## 197. 建立 `titanic` 專家模型\n",
    "\n",
    "定義類別 `ExpertModelTitanic` 用來建立具有兩個方法 `fit()`、`predict()` 的物件，能夠依據 `split_train_valid_titanic()` 函數所輸出 $X^{train}$ 與 $y^{train}$ 建立專家模型，`Sex` 為 `0` 或者 `Age` 小於平均就預測 $\\hat{y}$ 為 `1`，否則預測為 `0`\n",
    "\n",
    "- 使用 `self`\n",
    "- 以 `self.attribute` 在類別程式區塊中使用屬性。\n",
    "- 以 `self.method()` 在類別程式區塊中使用方法。\n",
    "- 使用 `wrangle_feature_matrix_titanic()` 函數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "a3e2182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpertModelTitanic:\n",
    "    \"\"\"\n",
    "    >>> y, X = extract_target_array_feature_matrix_titanic()\n",
    "    >>> X_wrangled = wrangle_feature_matrix_titanic(X)\n",
    "    >>> X_train, X_valid, y_train, y_valid = split_train_valid_titanic(X_wrangled, y)\n",
    "    >>> expert_model_titanic = ExpertModelTitanic()\n",
    "    >>> expert_model_titanic.fit(X_train)\n",
    "    >>> y_hat = expert_model_titanic.predict(X_valid)\n",
    "    >>> type(y_hat)\n",
    "    numpy.ndarray\n",
    "    >>> y_hat.shape\n",
    "    (268,)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    def fit(self, X_train):\n",
    "        self.X_train_sex = X_train[:,0]\n",
    "        self.X_train_age = X_train[:,1]\n",
    "        self.age_mean = self.X_train_age.mean()\n",
    "    def predict(self, X_valid):\n",
    "        Con1 = X_valid[:,0] == 0\n",
    "        Con2 = X_valid[:,1] < self.age_mean\n",
    "        y_hat = np.where(np.logical_or(Con1, Con2), 1, 0)\n",
    "        return y_hat\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "9fb535b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y, X = extract_target_array_feature_matrix_titanic()\n",
    "# X_wrangled = wrangle_feature_matrix_titanic(X)\n",
    "# X_train, X_valid, y_train, y_valid = split_train_valid_titanic(X_wrangled, y)\n",
    "# expert_model_titanic = ExpertModelTitanic()\n",
    "# expert_model_titanic.fit(X_train)\n",
    "# y_hat = expert_model_titanic.predict(X_valid)\n",
    "# y_hat.shape\n",
    "# type(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f1953d",
   "metadata": {},
   "source": [
    "## 198. 建立 `titanic` 基於機器學習的模型\n",
    "\n",
    "定義類別 `MachineLearningModelTitanic` 用來建立具有兩個方法 `fit()`、`predict()` 的物件，能夠依據 `split_train_valid_titanic()` 函數所輸出 $X^{train}$ 與 $y^{train}$ 建立基於機器學習的模型，直接使用 Scikit-Learn `LogisticRegression` 類別 `fit()` 與 `predict()` 方法預測 $\\hat{y}$\n",
    "\n",
    "- 使用 `self`\n",
    "- 以 `self.attribute` 在類別程式區塊中使用屬性。\n",
    "- 以 `self.method()` 在類別程式區塊中使用方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "81f9811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MachineLearningModelTitanic:\n",
    "    \"\"\"\n",
    "    >>> y, X = extract_target_array_feature_matrix_titanic()\n",
    "    >>> X_wrangled = wrangle_feature_matrix_titanic(X)\n",
    "    >>> X_train, X_valid, y_train, y_valid = split_train_valid_titanic(X_wrangled, y)\n",
    "    >>> machine_learning_model_titanic = MachineLearningModelTitanic()\n",
    "    >>> machine_learning_model_titanic.fit(X_train, y_train)\n",
    "    LogisticRegression()\n",
    "    >>> y_hat = machine_learning_model_titanic.predict(X_valid)\n",
    "    >>> type(y_hat)\n",
    "    numpy.ndarray\n",
    "    >>> y_hat.shape\n",
    "    (268,)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.lr = LogisticRegression()\n",
    "        self.lr.fit(X_train, y_train)\n",
    "        return self.lr\n",
    "    def predict(self, X_valid):\n",
    "        y_hat = self.lr.predict(X_valid)\n",
    "        return y_hat\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "797f0a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268,)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y, X = extract_target_array_feature_matrix_titanic()\n",
    "# X_wrangled = wrangle_feature_matrix_titanic(X)\n",
    "# X_train, X_valid, y_train, y_valid = split_train_valid_titanic(X_wrangled, y)\n",
    "# machine_learning_model_titanic = MachineLearningModelTitanic()\n",
    "# machine_learning_model_titanic.fit(X_train, y_train)\n",
    "# y_hat = machine_learning_model_titanic.predict(X_valid)\n",
    "# type(y_hat)\n",
    "# y_hat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db637f0d",
   "metadata": {},
   "source": [
    "## 199. 驗證 `titanic` 的三個模型\n",
    "\n",
    "定義函數 `validate_model_performance_titanic()` 能夠依據 `split_train_valid_titanic()` 函數所輸出 $y^{valid}$，計算虛假模型、專家模型與基於機器學習模型的表現評估。\n",
    "\n",
    "- 計算誤分類數。\n",
    "- 將預期輸出寫在 `return` 之後。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d151d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model_performance_titanic(dummy_y_hat: np.ndarray,\n",
    "                                       expert_y_hat: np.ndarray,\n",
    "                                       machine_learning_y_hat: np.ndarray,\n",
    "                                       y_valid: np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    >>> y, X = extract_target_array_feature_matrix_titanic()\n",
    "    >>> X_wrangled = wrangle_feature_matrix_titanic(X)\n",
    "    >>> X_train, X_valid, y_train, y_valid = split_train_valid_titanic(X_wrangled, y)\n",
    "    >>> dummy_model_titanic = DummyModelTitanic()\n",
    "    >>> dummy_model_titanic.fit(y_train)\n",
    "    >>> dummy_y_hat = dummy_model_titanic.predict(X_valid)\n",
    "    >>> expert_model_titanic = ExpertModelTitanic()\n",
    "    >>> expert_model_titanic.fit(X_train)\n",
    "    >>> expert_y_hat = expert_model_titanic.predict(X_valid)\n",
    "    >>> machine_learning_model_titanic = MachineLearningModelTitanic()\n",
    "    >>> machine_learning_model_titanic.fit(X_train, y_train)\n",
    "    LinearRegression()\n",
    "    >>> machine_learning_y_hat = machine_learning_model_titanic.predict(X_valid)\n",
    "    >>> validate_model_performance_titanic(dummy_y_hat, expert_y_hat, machine_learning_y_hat, y_valid)\n",
    "    {'dummy': 118, 'expert': 100, 'machine_learning': 56}\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    result = dict() #sum 可以把下面三行檢查完之後符合資格的話，持續加上去\n",
    "    dummy_y_hat_error = sum(1 for i in range(len(dummy_y_hat)) if dummy_y_hat[i] != y_valid[i])\n",
    "    expert_y_hat_error = sum(1 for i in range(len(expert_y_hat)) if expert_y_hat[i] != y_valid[i])\n",
    "    machine_learning_y_hat_error = sum(1 for i in range(len(machine_learning_y_hat)) if machine_learning_y_hat[i] != y_valid[i])\n",
    "    result = {'dummy':dummy_y_hat_error, 'expert':expert_y_hat_error, 'machine_learning':machine_learning_y_hat_error}\n",
    "    return result\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b80717c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dummy': 128, 'expert': 100, 'machine_learning': 56}"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y, X = extract_target_array_feature_matrix_titanic()\n",
    "# X_wrangled = wrangle_feature_matrix_titanic(X)\n",
    "# X_train, X_valid, y_train, y_valid = split_train_valid_titanic(X_wrangled, y)\n",
    "# dummy_model_titanic = DummyModelTitanic()\n",
    "# dummy_model_titanic.fit(y_train)\n",
    "# dummy_y_hat = dummy_model_titanic.predict(X_valid)\n",
    "# expert_model_titanic = ExpertModelTitanic()\n",
    "# expert_model_titanic.fit(X_train)\n",
    "# expert_y_hat = expert_model_titanic.predict(X_valid)\n",
    "# machine_learning_model_titanic = MachineLearningModelTitanic()\n",
    "# machine_learning_model_titanic.fit(X_train, y_train)\n",
    "# LinearRegression()\n",
    "# machine_learning_y_hat = machine_learning_model_titanic.predict(X_valid)\n",
    "# validate_model_performance_titanic(dummy_y_hat, expert_y_hat, machine_learning_y_hat, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d853501",
   "metadata": {},
   "source": [
    "## 200. 以 `titanic` 機器學習模型預測位於 `/home/jovyan/data/titanic` 路徑的 `test.csv`\n",
    "\n",
    "定義函數 `predict_survived()` 能夠依據 `Age`、`Sex` 與基於機器學習的模型預測 `test.csv` 的 `Survived` 並以 `submission_titanic.csv` 格式匯出至工作目錄。\n",
    "\n",
    "- 使用 `import_titanic()` 函數。\n",
    "- 使用 `extract_target_array_feature_matrix_titanic()` 函數。\n",
    "- 使用 `wrangle_feature_matrix_titanic()` 函數。\n",
    "- 使用 `split_train_valid_titanic()` 函數。\n",
    "- 使用 `MachineLearningModelTitanic` 類別。\n",
    "- 使用 `DataFrame.to_csv(\"submission_titanic.csv\", index=False)`\n",
    "- 將預期輸出寫在 `return` 之後。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "325d9dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_survived(X_test: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    >>> train, test = import_titanic()\n",
    "    >>> X_test = test[[\"PassengerId\", \"Sex\", \"Age\"]]\n",
    "    >>> predict_survived(X_test)\n",
    "         PassengerId  Survived\n",
    "    0            892         0\n",
    "    1            893         1\n",
    "    2            894         0\n",
    "    3            895         0\n",
    "    4            896         1\n",
    "    ..           ...       ...\n",
    "    413         1305         0\n",
    "    414         1306         1\n",
    "    415         1307         0\n",
    "    416         1308         0\n",
    "    417         1309         0\n",
    "\n",
    "    [418 rows x 2 columns]\n",
    "    >>> submission_csv = pd.read_csv(\"submission_titanic.csv\")\n",
    "    >>> submission_csv.shape\n",
    "    (418, 2)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    y, X = extract_target_array_feature_matrix_titanic()\n",
    "    X = wrangle_feature_matrix_titanic(X)\n",
    "    X_train, X_valid, y_train, y_valid = split_train_valid_titanic(X, y)\n",
    "    #其他類別的東西要先實例化：\n",
    "    machine_learning_model_titanic = MachineLearningModelTitanic()\n",
    "    machine_learning_model_titanic.fit(X_train, y_train)\n",
    "    X_test_data = X_test[['Sex', 'Age']].values\n",
    "    X_test_data = wrangle_feature_matrix_titanic(X_test_data)\n",
    "    result = machine_learning_model_titanic.predict(X_test_data)\n",
    "    result_df = pd.DataFrame({'PassengerId': X_test['PassengerId'], 'Survived':result})\n",
    "    result_df.to_csv('submission_titanic.csv', index=False)\n",
    "    return result_df\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "5b7199fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 2)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, test = import_titanic()\n",
    "# X_test = test[[\"PassengerId\", \"Sex\", \"Age\"]]\n",
    "# predict_survived(X_test)\n",
    "# submission_csv = pd.read_csv(\"submission_titanic.csv\")\n",
    "# submission_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2940a28f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
